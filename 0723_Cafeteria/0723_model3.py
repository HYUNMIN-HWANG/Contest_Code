import pandas as pd
import numpy as np
import xgboost

#1. DATA
train = pd.read_csv('../data/DACON/cafeteria_prediction/train.csv')
test = pd.read_csv('../data/DACON/cafeteria_prediction/test.csv')
submission = pd.read_csv('../data/DACON/cafeteria_prediction/sample_submission.csv')

print(train.shape)  # (1205, 12)
print(test.shape)   # (50, 10)
print(submission.shape) # (50, 3)


# ë©”ë‰´ ì´ë¦„ ë¹¼ê¸°
drops = ['ì¡°ì‹ë©”ë‰´', 'ì¤‘ì‹ë©”ë‰´', 'ì„ì‹ë©”ë‰´']

train = train.drop(drops, axis=1)
test = test.drop(drops, axis=1)

# ìš”ì¼ -> ìˆ«ì
train['ì›”'] = pd.DatetimeIndex(train['ì¼ì']).month
test['ì›”'] = pd.DatetimeIndex(test['ì¼ì']).month

train['ì¼'] = pd.DatetimeIndex(train['ì¼ì']).day
test['ì¼'] = pd.DatetimeIndex(test['ì¼ì']).day

weekday = {
    'ì›”': 1,
    'í™”': 2,
    'ìˆ˜': 3,
    'ëª©': 4,
    'ê¸ˆ': 5
}

train['ìš”ì¼'] = train['ìš”ì¼'].map(weekday)
test['ìš”ì¼'] = test['ìš”ì¼'].map(weekday)

# ë³¸ì‚¬ì •ì›ìˆ˜ - íœ´ê°€ì - ì¬íƒê·¼ë¬´ì
train['ì‹ì‚¬ê°€ëŠ¥ììˆ˜'] = train['ë³¸ì‚¬ì •ì›ìˆ˜'] - train['ë³¸ì‚¬íœ´ê°€ììˆ˜'] - train['í˜„ë³¸ì‚¬ì†Œì†ì¬íƒê·¼ë¬´ììˆ˜']
test['ì‹ì‚¬ê°€ëŠ¥ììˆ˜'] = test['ë³¸ì‚¬ì •ì›ìˆ˜'] - test['ë³¸ì‚¬íœ´ê°€ììˆ˜'] - test['í˜„ë³¸ì‚¬ì†Œì†ì¬íƒê·¼ë¬´ììˆ˜']

train['ì¤‘ì‹ì°¸ì—¬ìœ¨'] = train['ì¤‘ì‹ê³„'] / train['ì‹ì‚¬ê°€ëŠ¥ììˆ˜']
train['ì„ì‹ì°¸ì—¬ìœ¨'] = train['ì„ì‹ê³„'] / train['ì‹ì‚¬ê°€ëŠ¥ììˆ˜']

features = ['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']
labels = ['ì¤‘ì‹ê³„',	'ì„ì‹ê³„', 'ì¤‘ì‹ì°¸ì—¬ìœ¨', 'ì„ì‹ì°¸ì—¬ìœ¨']

train = train[features+labels]
test = test[features]

# print(train[:20])
# print(test.head())

# Modeling
from sklearn.ensemble import RandomForestRegressor
from catboost import CatBoostRegressor
from lightgbm import LGBMRegressor
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from sklearn.model_selection import GridSearchCV
from mlxtend.regressor import StackingCVRegressor
from sklearn.linear_model import Lasso
import xgboost as xgb

RANDOM_SEED = 2021
PROBAS = True
FOLDS = 8
N_ESTIMATORS = 1000
lasso = Lasso()

# ëŒ€íšŒ ê·œì¹™
# í‰ê°€ì‚°ì‹ : MAE(Mean Absolute Error)

XGB_params = {
    'learning_rate': [0.0, 0.1, 0.09, 0.089, 0.08]
}

# ê²°ê³¼ë¥¼ ì„ì‹œë¡œ ì €ì¥í•  í”„ë ˆì„
temp_result = pd.DataFrame(index=['ì¼ì','ì¤‘ì‹ê³„','ì„ì‹ê³„','ìš”ì¼'])
print(temp_result.shape)
print(temp_result)

lunch_r = XGBRegressor(objective='reg:squarederror')
dinner_r = XGBRegressor(objective='reg:squarederror')

lunch_model = GridSearchCV(lunch_r, XGB_params, scoring='neg_mean_absolute_error')
dinner_model = GridSearchCV(dinner_r, XGB_params, scoring='neg_mean_absolute_error')

lunch_cat = CatBoostRegressor(n_estimators=1000)
dinner_cat = CatBoostRegressor(n_estimators=1000)

lunch_LGBM = LGBMRegressor(n_estimators=1000)
dinner_LGBM = LGBMRegressor(n_estimators=1000)

lunch_KN = KNeighborsRegressor(n_neighbors = 1)
dinner_KN = KNeighborsRegressor(n_neighbors = 1)

lunch_xgb = xgb.XGBRegressor(n_esimators=1000)
dinner_xgb = xgb.XGBRegressor(n_esimators=1000)

lunch_rfr = RandomForestRegressor(criterion='mae',n_jobs=-1, random_state=42)
dinner_rfr = RandomForestRegressor(criterion='mae',n_jobs=-1, random_state=42)

lunch_stack = StackingCVRegressor(regressors=(lunch_model, lunch_cat, lunch_LGBM, lunch_KN, lunch_xgb, lunch_rfr),
                            meta_regressor=lasso,
                            random_state=RANDOM_SEED)

dinner_stack = StackingCVRegressor(regressors=(dinner_model, dinner_cat, dinner_LGBM, dinner_KN, dinner_xgb, dinner_rfr),
                            meta_regressor=lasso,
                            random_state=RANDOM_SEED)                            

# ì¤‘ì‹
x = train[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
y = train['ì¤‘ì‹ê³„']

lunch_stack.fit(x, y)

test_x = test[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
y_pred = lunch_stack.predict(test_x)
submission['ì¤‘ì‹ê³„'] = y_pred

print("====================================================")

# ì„ì‹
x = train[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
y = train['ì„ì‹ê³„']

dinner_stack.fit(x, y)

test_x = test[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
y_pred = dinner_stack.predict(test_x)
submission['ì„ì‹ê³„'] = y_pred

print("=========================================")

submission.to_csv('../data/DACON/cafeteria_prediction/sub/0723_submit3.csv', index=False)
print(submission.shape)   # (50, 3)
print(submission.head())
#            ì¼ì          ì¤‘ì‹ê³„         ì„ì‹ê³„
# 0  2021-01-27  1002.767662  194.882100
# 1  2021-01-28   956.107734  498.568662
# 2  2021-01-29   599.198342  232.690510
# 3  2021-02-01  1227.568565  559.975478
# 4  2021-02-02  1069.583782  574.543574


print(" ğŸ’¯ğŸ’¯ğŸ’¯ğŸ’¯ Done!!! ") 

# 0723_submit3.csv
# 68.4240276214
import pandas as pd
import numpy as np

#1. DATA
train = pd.read_csv('../data/DACON/cafeteria_prediction/train.csv')
test = pd.read_csv('../data/DACON/cafeteria_prediction/test.csv')
submission = pd.read_csv('../data/DACON/cafeteria_prediction/sample_submission.csv')

print(train.shape)  # (1205, 12)
print(test.shape)   # (50, 10)
print(submission.shape) # (50, 3)


# ë©”ë‰´ ì´ë¦„ ë¹¼ê¸°
drops = ['ì¡°ì‹ë©”ë‰´', 'ì¤‘ì‹ë©”ë‰´', 'ì„ì‹ë©”ë‰´']

train = train.drop(drops, axis=1)
test = test.drop(drops, axis=1)

# ìš”ì¼ -> ìˆ«ì
train['ì›”'] = pd.DatetimeIndex(train['ì¼ì']).month
test['ì›”'] = pd.DatetimeIndex(test['ì¼ì']).month

train['ì¼'] = pd.DatetimeIndex(train['ì¼ì']).day
test['ì¼'] = pd.DatetimeIndex(test['ì¼ì']).day

weekday = {
    'ì›”': 1,
    'í™”': 2,
    'ìˆ˜': 3,
    'ëª©': 4,
    'ê¸ˆ': 5
}

train['ìš”ì¼'] = train['ìš”ì¼'].map(weekday)
test['ìš”ì¼'] = test['ìš”ì¼'].map(weekday)

# ë³¸ì‚¬ì •ì›ìˆ˜ - íœ´ê°€ì - ì¬íƒê·¼ë¬´ì
train['ì‹ì‚¬ê°€ëŠ¥ììˆ˜'] = train['ë³¸ì‚¬ì •ì›ìˆ˜'] - train['ë³¸ì‚¬íœ´ê°€ììˆ˜'] - train['í˜„ë³¸ì‚¬ì†Œì†ì¬íƒê·¼ë¬´ììˆ˜']
test['ì‹ì‚¬ê°€ëŠ¥ììˆ˜'] = test['ë³¸ì‚¬ì •ì›ìˆ˜'] - test['ë³¸ì‚¬íœ´ê°€ììˆ˜'] - test['í˜„ë³¸ì‚¬ì†Œì†ì¬íƒê·¼ë¬´ììˆ˜']

train['ì¤‘ì‹ì°¸ì—¬ìœ¨'] = train['ì¤‘ì‹ê³„'] / train['ì‹ì‚¬ê°€ëŠ¥ììˆ˜']
train['ì„ì‹ì°¸ì—¬ìœ¨'] = train['ì„ì‹ê³„'] / train['ì‹ì‚¬ê°€ëŠ¥ììˆ˜']

features = ['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']
labels = ['ì¤‘ì‹ê³„',	'ì„ì‹ê³„', 'ì¤‘ì‹ì°¸ì—¬ìœ¨', 'ì„ì‹ì°¸ì—¬ìœ¨']

train = train[features+labels]
test = test[features]

# print(train[:20])
# print(test.head())

# Modeling
from sklearn.ensemble import RandomForestRegressor

# ëŒ€íšŒ ê·œì¹™
# í‰ê°€ì‚°ì‹ : MAE(Mean Absolute Error)
lunch_model = RandomForestRegressor(criterion='mae')
dinner_model = RandomForestRegressor(criterion='mae')

from sklearn.model_selection import GridSearchCV
from xgboost import XGBRegressor

params = {
    'learning_rate': [0.0, 0.1, 0.09, 0.089, 0.08],
    'boosting_type': ['gbtree', 'gblinear', 'dart']
}

lunch_r = XGBRegressor(objective='reg:squarederror')
dinner_r = XGBRegressor(objective='reg:squarederror')

lunch_model = GridSearchCV(lunch_r, params, scoring='neg_mean_absolute_error')
dinner_model = GridSearchCV(dinner_r, params, scoring='neg_mean_absolute_error')


# ìš”ì¼ë³„ë¡œ ì˜¤ë¦„ì°¨ìˆœ
train = train.sort_values(by='ìš”ì¼', ascending=True)
test = test.sort_values(by='ìš”ì¼', ascending=True)
submission['ìš”ì¼'] = test['ìš”ì¼']   # submission ì—ë„ 'ìš”ì¼' ì»¬ëŸ¼ ì¶”ê°€
submission = submission.sort_values(by='ìš”ì¼', ascending=True)
# print(test[:10])
# print(submission[:10])

# ê²°ê³¼ë¥¼ ì„ì‹œë¡œ ì €ì¥í•  í”„ë ˆì„
temp_result = pd.DataFrame(index=['ì¼ì','ì¤‘ì‹ê³„','ì„ì‹ê³„','ìš”ì¼'])
print(temp_result.shape)
print(temp_result)


# ìš”ì¼ë³„ë¡œ ë¶„ì„í•˜ê¸°
for day in range(1,6):

    params = {
        'learning_rate': [0.0, 0.1, 0.09, 0.089, 0.08],
        'boosting_type': ['gbtree', 'gblinear', 'dart']
    }

    lunch_r = XGBRegressor(objective='reg:squarederror')
    dinner_r = XGBRegressor(objective='reg:squarederror')

    lunch_model = GridSearchCV(lunch_r, params, scoring='neg_mean_absolute_error')
    dinner_model = GridSearchCV(dinner_r, params, scoring='neg_mean_absolute_error')

    # ìš”ì¼ë³„ë¡œ ë¶„ì„í•˜ê¸°        
    print(day, "ìš”ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ===================")

    train_day = train[train['ìš”ì¼'] == day]
    print(train_day.shape)
    # print(train_day[:10])
    # 1 ìš”ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
    # (241, 10)
    # 2 ìš”ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
    # (240, 10)
    # 3 ìš”ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
    # (239, 10)
    # 4 ìš”ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
    # (244, 10)
    # 5 ìš”ì¼ ë°ì´í„°ë§Œ ì¶”ì¶œ
    # (241, 10)

    # ì˜ˆì¸¡ ë°ì´í„°
    test_day = test[test['ìš”ì¼'] == day]
    print(test_day.shape)
    predict_day = submission[submission['ìš”ì¼'] == day]
    print(predict_day.shape)

    # ì¤‘ì‹
    x = train_day[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
    y = train_day['ì¤‘ì‹ê³„']
    print(x.shape, y.shape)

    lunch_model.fit(x, y)
    print(lunch_model.best_score_, lunch_model.best_params_)
    lunch_model = lunch_model.best_estimator_

    test_x = test_day[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
    y_pred = lunch_model.predict(test_x)
    predict_day['ì¤‘ì‹ê³„'] = y_pred
    print(predict_day)

    # ì¤‘ì‹
    x = train_day[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
    y = train_day['ì„ì‹ê³„']
    print(x.shape, y.shape)

    dinner_model.fit(x, y)
    print(dinner_model.best_score_, dinner_model.best_params_)
    dinner_model = dinner_model.best_estimator_

    test_x = test_day[['ì›”', 'ì¼', 'ìš”ì¼', 'ì‹ì‚¬ê°€ëŠ¥ììˆ˜', 'ë³¸ì‚¬ì¶œì¥ììˆ˜', 'ë³¸ì‚¬ì‹œê°„ì™¸ê·¼ë¬´ëª…ë ¹ì„œìŠ¹ì¸ê±´ìˆ˜']]
    y_pred = dinner_model.predict(test_x)
    predict_day['ì„ì‹ê³„'] = y_pred
    print(predict_day)

    temp_result = pd.concat([temp_result, predict_day])

    # print(temp_result)

final_submission = temp_result.drop('ìš”ì¼', axis=1)
final_submission = final_submission.sort_values(by='ì¼ì', ascending=True)
final_submission = final_submission[:-4]
print(final_submission)


print("=========================================")

final_submission.to_csv('../data/DACON/cafeteria_prediction/sub/0721_submit1.csv', index=False)
print(final_submission.shape)
print(final_submission.head())
#            ì¼ì          ì¤‘ì‹ê³„         ì„ì‹ê³„
# 0  2021-01-27  1074.606079  456.600281
# 1  2021-01-28   945.466675  437.640320
# 2  2021-01-29   534.854736  216.664780
# 3  2021-02-01  1096.341797  449.633301
# 4  2021-02-02   957.244629  552.495422

print(" ğŸ’¯ğŸ’¯ğŸ’¯ğŸ’¯ Done!!! ") 

# 0721_submit1.csv
# 73.6761986667	